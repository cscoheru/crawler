# 系统架构设计文档

## 1. 系统概述

### 1.1 项目定位
爬虫数据管理与内容创作系统是一个多层次的内容爬取、分类、管理和创作的云平台，部署在 Railway 上。

### 1.2 技术栈
| 层级 | 技术 |
|------|------|
| 前端 | Streamlit |
| 后端 | Python (Flask + APScheduler) |
| 数据库 | SQLAlchemy ORM (SQLite/PostgreSQL) |
| AI服务 | 智谱 GLM / DeepSeek |
| 知识库 | Dify |
| 部署 | Railway |

---

## 2. 系统架构图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              外部数据源层                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│  知乎    │ 头条    │ 微信公众号  │ B站  │ 得到  │ 喜马拉雅  │ Dify知识库     │
└─────────────────────────────────────────────────────────────────────────────┘
                                         │
                                         ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                              爬虫层 (Crawler Layer)                         │
├─────────────────────────────────────────────────────────────────────────────┤
│  BaseCrawler (抽象基类)                                                      │
│    ├── ZhihuCrawler       ├── ToutiaoCrawler                                │
│    ├── WeChatCrawler      ├── BilibiliCrawler                               │
│    ├── DedaoCrawler       ├── XimalayaCrawler                               │
│                                                                              │
│  功能: 搜索API调用、文章详情获取、数据标准化、反爬虫处理                      │
└─────────────────────────────────────────────────────────────────────────────┘
                                         │
                                         ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                           数据处理层 (Processing Layer)                      │
├─────────────────────────────────────────────────────────────────────────────┤
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐              │
│  │  TextCleaner    │  │   Classifier    │  │  DifyBatchSyncer│              │
│  │                 │  │                 │  │                 │              │
│  │ • HTML清理      │  │ • RuleBased     │  │ • 知识库同步     │              │
│  │ • 文本清洗      │  │ • MultiLevel    │  │ • 文档上传       │              │
│  │ • 去重处理      │  │ • Hybrid        │  │ • 批量操作       │              │
│  │ • 质量评分      │  │ • AI (可选)     │  │                 │              │
│  │ • 垃圾内容检测  │  │                 │  │                 │              │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘              │
└─────────────────────────────────────────────────────────────────────────────┘
                                         │
                                         ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                           存储层 (Storage Layer)                            │
├─────────────────────────────────────────────────────────────────────────────┤
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐              │
│  │ DatabaseManager │  │  文件存储        │  │ Dify知识库      │              │
│  │ (SQLAlchemy)    │  │                 │  │                 │              │
│  │                 │  │ • /data/raw     │  │ • 文档管理       │              │
│  │ • Article       │  │ • /data/processed│ │ • 向量检索       │              │
│  │ • CrawlLog      │  │ • /data/exports │  │                 │              │
│  │ • Keyword       │  │ • /logs         │  │                 │              │
│  │ • CreatedArticle│  │                 │  │                 │              │
│  │ • TaskLog       │  │                 │  │                 │              │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘              │
└─────────────────────────────────────────────────────────────────────────────┘
                                         │
                                         ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                        API服务层 (API Service Layer)                        │
├─────────────────────────────────────────────────────────────────────────────┤
│  Flask Web Server (web_server.py)                                           │
│                                                                              │
│  GET  /health              - 健康检查                                       │
│  GET  /api/stats           - 数据库统计                                     │
│  POST /api/crawl           - 手动触发爬虫                                   │
│  POST /api/export          - 导出数据 (TXT/JSON/CSV)                        │
│  POST /api/sync-dify       - 同步到Dify知识库                               │
│  POST /api/run-full-sync   - 完整同步流程                                   │
└─────────────────────────────────────────────────────────────────────────────┘
                                         │
                                         ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                        调度层 (Scheduler Layer)                             │
├─────────────────────────────────────────────────────────────────────────────┤
│  CrawlerScheduler (APScheduler - AsyncIOScheduler)                          │
│                                                                              │
│  定时任务:                                                                   │
│  • 知乎爬取    (06:00)   • 头条爬取    (08:00)                               │
│  • 微信爬取    (10:00)   • B站爬取     (12:00)                               │
│  • 得到爬取    (13:00)   • 喜马拉雅    (13:30)                               │
│  • 文章分类    (14:00)   • Dify同步    (15:00)                               │
│  • 质量检查    (20:00)                                                   │
└─────────────────────────────────────────────────────────────────────────────┘
                                         │
                                         ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                        前端层 (Frontend Layer)                              │
├─────────────────────────────────────────────────────────────────────────────┤
│  Streamlit 前端应用 (由前端工程师负责)                                       │
│                                                                              │
│  功能: 数据浏览、文章管理、统计仪表盘、创作任务管理                          │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 3. 数据流图

### 3.1 爬取数据流

```
外部平台API
    │
    ▼
爬虫模块 (crawler/*.py)
    │
    ▼
原始数据
    │
    ▼
TextCleaner (清洗、去重、质量评分)
    │
    ▼
过滤后的数据
    │
    ▼
Classifier (三级分类)
    │
    ▼
已分类数据
    │
    ├─────────────────┬─────────────────┐
    ▼                 ▼                 ▼
SQLite/PG         文件导出         Dify同步
```

### 3.2 创作数据流

```
用户请求
    │
    ▼
Streamlit前端
    │
    ▼
API请求
    │
    ├─────────────┐
    ▼             ▼
查询相似文章    构建Prompt
    │             │
    └─────────────┘
                  │
                  ▼
          调用AI创作 (GLM/DeepSeek)
                  │
                  ▼
          保存创作结果
                  │
                  ▼
          支持多种格式导出
```

---

## 4. 部署架构图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           Railway 云端部署                                   │
└─────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│  Railway Web Service                                                       │
│                                                                             │
│  Docker Container (Python 3.11)                                            │
│  ├── Gunicorn (1 worker, 600s timeout)                                     │
│  ├── Flask Web Server (web_server.py)                                      │
│  ├── DatabaseManager (SQLite/PostgreSQL)                                   │
│  └── 健康检查: /health (30s间隔)                                            │
│                                                                             │
│  环境变量:                                                                  │
│  • DATABASE_URL, DIFY_API_KEY, DIFY_BASE_URL                               │
│  • ZHIPUAI_API_KEY, DEEPSEEK_API_KEY, LOG_LEVEL                            │
└─────────────────────────────────────────────────────────────────────────────┘
                                 │
                                 │ GitHub Actions (定时触发)
                                 ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  GitHub Actions (.github/workflows/trigger-crawler.yml)                    │
│                                                                             │
│  触发: POST /api/run-full-sync                                              │
│  执行: 爬取 → 分类 → 导出 → Dify同步                                         │
│  调度: 每日 UTC 8:00 (北京时间 16:00)                                        │
└─────────────────────────────────────────────────────────────────────────────┘
                                 │
                                 ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  外部服务集成                                                               │
│                                                                             │
│  Dify 知识库: 通过 API 同步文章                                             │
│  AI 服务: 智谱 GLM / DeepSeek (可选)                                        │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 5. 安全架构图

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                           安全措施                                          │
└──────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│  网络安全                                                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│  • HTTPS 通信 (Railway 自动提供)                                           │
│  • API 密钥通过环境变量管理，不硬编码                                        │
│  • 反爬虫机制: User-Agent轮换、请求延迟、代理池支持                          │
│  • 请求超时控制 (30s)                                                       │
└─────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│  数据安全                                                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│  • 数据库唯一约束 (source + article_id)                                     │
│  • SQL注入防护 (SQLAlchemy ORM)                                            │
│  • 垃圾内容检测 (EXCLUSION_KEYWORDS)                                       │
│  • 内容质量评分过滤 (quality_score >= 0.5)                                  │
│  • 数据清洗去重                                                             │
└─────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│  日志审计                                                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│  • Loguru 日志系统                                                          │
│  • 日志文件轮转 (100MB/文件, 30天保留)                                       │
│  • 爬取日志记录 (CrawlLog表)                                                │
│  • 错误追踪和记录                                                           │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 6. 组件说明

### 6.1 爬虫层 (`crawler/`)

| 组件 | 文件 | 功能 |
|------|------|------|
| BaseCrawler | base.py | 抽象基类，定义爬虫接口 |
| ZhihuCrawler | zhihu.py | 知乎文章爬取 |
| ToutiaoCrawler | toutiao.py | 今日头条文章爬取 |
| WeChatCrawler | wechat.py | 微信公众号文章爬取 |
| BilibiliCrawler | bilibili.py | B站视频爬取 |
| DedaoCrawler | dedao.py | 得到课程爬取 |
| XimalayaCrawler | ximalaya.py | 喜马拉雅音频爬取 |

### 6.2 分类层 (`classifier/`)

| 组件 | 文件 | 功能 |
|------|------|------|
| RuleBasedClassifier | rule_based.py | 规则分类器 |
| MultiLevelClassifier | multi_level_classifier.py | 三级分类器 |
| HybridClassifier | ai_classifier.py | 混合分类器 |

### 6.3 存储层 (`storage/`)

| 组件 | 文件 | 功能 |
|------|------|------|
| DatabaseManager | database.py | 数据库管理器 |
| Article | models.py | 文章模型 |
| CrawlLog | models.py | 爬取日志模型 |
| Keyword | models.py | 关键词模型 |

### 6.4 工具层 (`utils/`)

| 组件 | 文件 | 功能 |
|------|------|------|
| TextCleaner | text_cleaner.py | 文本清洗 |
| DifyBatchSyncer | dify_integration.py | Dify 同步 |
| AntiSpider | anti_spider.py | 反爬虫处理 |
| ProxyPool | proxy_pool.py | 代理池管理 |

---

## 7. 关键文件路径

| 文件 | 路径 | 描述 |
|------|------|------|
| 主入口 | main.py | CLI 入口 |
| Web服务器 | web_server.py | Flask API 服务 |
| 调度器 | scheduler/jobs.py | 定时任务定义 |
| 数据库模型 | storage/models.py | ORM 模型定义 |
| 配置文件 | config/settings.py | 全局配置 |

---

**文档版本**: v1.0
**最后更新**: 2024-02-26
